{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HitLogID': 0, 'UniqID': 1, 'IsClick': 2, 'ShowTime': 3, 'PhraseID': 4, 'TargetDomainID': 5, 'PageID': 6, 'OrderID': 7, 'BannerID': 8, 'QueryLemmaH': 9, 'BannerTitleLemmaH': 10, 'DeviceType': 11, 'RegionID': 12}\n",
      "['PageID', 'OrderID', 'IsClick']\n",
      "['PageID', 'OrderID']\n",
      "[[258763, 18951888, 0], [264633, 14829991, 1], [249430, 1026618, 0], [261025, 19335144, 1]]\n"
     ]
    }
   ],
   "source": [
    "filename = \"net_20180312_201803114_1k\"\n",
    "features = \"PageID OrderID\".split()\n",
    "target = \"IsClick\"\n",
    "columns = features + [target]\n",
    "data = []\n",
    "with open(filename) as fd:\n",
    "    header = fd.readline()[2:].strip().split(\"\\t\")\n",
    "    col_to_index = dict((col, i) for i, col in enumerate(header))\n",
    "    print(col_to_index)\n",
    "    column_indices = [col_to_index[col] for col in columns]\n",
    "    for line in fd:\n",
    "        splitted = line.strip().split(\"\\t\")\n",
    "        data.append([int(splitted[idx]) for idx in column_indices])\n",
    "print(columns)\n",
    "print(features)\n",
    "print(data[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate feature map and filter rare features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features = 168\n"
     ]
    }
   ],
   "source": [
    "# Calculate feature map via simple enumeration\n",
    "from collections import defaultdict\n",
    "\n",
    "feature_stats = defaultdict(dict)\n",
    "feature_map = defaultdict(dict)\n",
    "counter = 1\n",
    "for example in data:\n",
    "    for fid, col in zip(example[:-1], features):        \n",
    "        if fid not in feature_map[col]:\n",
    "            feature_map[col][fid] = counter\n",
    "            counter += 1\n",
    "        feature_stats[col][fid] = feature_stats[col].get(fid, 0) + 1\n",
    "\n",
    "#print(feature_stats)\n",
    "from collections import namedtuple\n",
    "Dataset = namedtuple(\"Dataset\", \"X y\")\n",
    "\n",
    "# remap features using feature map + filter rare features \n",
    "min_counts = 2\n",
    "X, y = [], []\n",
    "unk_fid = 0\n",
    "for rec in data:\n",
    "    X.append([feature_map[col][fid] if feature_stats[col][fid] >= min_counts else unk_fid \n",
    "                 for col, fid in zip(features, rec[:-1])])\n",
    "    y.append(rec[-1])\n",
    "dataset = Dataset(X, y)\n",
    "\n",
    "# calculate number of features\n",
    "num_features = 0\n",
    "for f, fdata in feature_stats.items():\n",
    "    for fid, counts in fdata.items():\n",
    "        if counts >= min_counts:\n",
    "            num_features += 1\n",
    "print(\"Number of features = {}\".format(num_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def batch_iter(dataset, batch_size):\n",
    "    for start in range(0, len(dataset.X), batch_size):\n",
    "        yield dataset.X[start:start + batch_size], dataset.y[start:start + batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class FFM(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(FFM, self).__init__()\n",
    "\n",
    "        self.num_features = kwargs[\"num_features\"]\n",
    "        self.dim = kwargs[\"dim\"]\n",
    "        self.embeddings = nn.Embedding(self.num_features, self.dim)\n",
    "        self.unary = nn.Embedding(self.num_features, 1)\n",
    "        self.num_fields = kwargs[\"num_fields\"]\n",
    "        #self.logsigmoid = nn.LogSigmoid()\n",
    "        \n",
    "        # initialize weights\n",
    "        glorot = math.sqrt(2.0 / (self.num_features * self.dim + 1.0))\n",
    "        self.embeddings.weight.data.uniform_(-glorot, glorot)\n",
    "        glorot = math.sqrt(2.0 / (self.num_features + 1.0))\n",
    "        self.unary.weight.data.uniform_(-glorot, glorot)\n",
    "\n",
    "        self.projection = nn.Linear(self.dim + self.num_fields, 1)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        :param self:\n",
    "        :param X: B (batch size) x F (number of features)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        embeddings = self.embeddings(X)  # B x F x D\n",
    "        embeddings_sum = embeddings.sum(dim=1)  # B x 1 x D\n",
    "        sum_squares = torch.mul(embeddings, embeddings).sum(dim=1)  # B x 1 x D\n",
    "        quadratic = 0.5 * (torch.mul(embeddings_sum, embeddings_sum) - sum_squares)\n",
    "        unary = self.unary(X)  # B x F x 1\n",
    "        unary = unary.squeeze(dim=2)\n",
    "        \n",
    "        concat = torch.cat((quadratic, unary), dim=1)\n",
    "        print(concat.size())\n",
    "        print(unary.size())\n",
    "        print(quadratic.size())\n",
    "        logsigmoid = nn.LogSigmoid()\n",
    "        return logsigmoid(concat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "torch.Size([64, 12])\n",
      "torch.Size([64, 2])\n",
      "torch.Size([64, 10])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "index out of range at /pytorch/torch/lib/TH/generic/THTensorMath.c:277",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-0c99398a1cc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mlogprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-5d9f1ae2848d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \"\"\"\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# B x F x D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0membeddings_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# B x 1 x D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0msum_squares\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# B x 1 x D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/playground/pytorch/pyenv3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/playground/pytorch/pyenv3/lib/python3.6/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         )\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/playground/pytorch/pyenv3/lib/python3.6/site-packages/torch/nn/_functions/thnn/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(cls, ctx, indices, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: index out of range at /pytorch/torch/lib/TH/generic/THTensorMath.c:277"
     ]
    }
   ],
   "source": [
    "USE_CUDA = False\n",
    "LongTensor = torch.cuda.LongTensor if USE_CUDA else torch.LongTensor\n",
    "\n",
    "conf = {\n",
    "    \"num_features\": num_features,\n",
    "    \"dim\": 10,\n",
    "    \"num_iter\": 1,\n",
    "    \"batch_size\": 64,\n",
    "    \"num_fields\": len(features)\n",
    "}\n",
    "num_iter = conf[\"num_iter\"]\n",
    "\n",
    "\n",
    "model = FFM(**conf)\n",
    "loss_func = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "for it in range(num_iter):\n",
    "    data_iter = batch_iter(dataset, batch_size=conf[\"batch_size\"])\n",
    "    print(\"Iteration {iter}\".format(iter=it))\n",
    "    for Xb, yb in data_iter:\n",
    "        targets = autograd.Variable(LongTensor(yb))\n",
    "        features = autograd.Variable(LongTensor(Xb))\n",
    "        \n",
    "        model.zero_grad()\n",
    "        logprob = model.forward(features)\n",
    "        loss = loss_func(logprob, targets)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
